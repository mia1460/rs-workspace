import pandas as pd
import numpy as np
import argparse
import matplotlib.pyplot as plt
from datetime import datetime
import json
import os
from collections import defaultdict
import matplotlib as mpl

def parse_arguments():
    parser = argparse.ArgumentParser(
        description='User Interaction Data Analysis and Visualization',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    
    parser.add_argument('input_file', help='Path to input CSV file')
    parser.add_argument('--delta_t', type=int, default=60000,
                      help='Time window size in milliseconds')
    parser.add_argument('--output_dir', default='./results',
                      help='Output directory path')
    parser.add_argument('--output_prefix', default='interaction_stats',
                      help='Prefix for output filenames')
    parser.add_argument('--time_col', default='time_ms',
                      help='Timestamp column name')
    parser.add_argument('--user_col', default='user_id',
                      help='User ID column name')
    parser.add_argument('--plot', action='store_true',
                      help='Generate visualization plots')
    
    return parser.parse_args()

def calculate_metrics(df, user_col):
    """Calculate key metrics"""
    metrics = {
        'total_interactions': len(df),
        'unique_users': df[user_col].nunique(),
        'avg_interactions_per_user': len(df) / df[user_col].nunique(),
        'interaction_counts': df[user_col].value_counts().to_dict()
    }
    return metrics

def analyze_data(df, delta_t_ms, time_col, user_col):
    """Analyze data with progress display"""
    print("\nðŸ” Starting data analysis...")
    
    # Data preprocessing
    print("â³ Preprocessing data (time conversion, sorting)...", end=' ', flush=True)
    df['timestamp'] = pd.to_datetime(df[time_col], unit='ms')
    df = df.sort_values('timestamp')
    min_time = df['timestamp'].min()
    df['time_since_start'] = (df['timestamp'] - min_time).dt.total_seconds() * 1000
    total_records = len(df)
    print(f"Done! Total {total_records:,} records")
    
    # Initialize time windows
    max_time = df['time_since_start'].max()
    time_windows = np.arange(0, max_time + delta_t_ms, delta_t_ms)
    total_windows = len(time_windows)
    print(f"â° Will analyze {total_windows} time windows ({delta_t_ms/1000:.1f}s each)")
    
    window_stats = []
    cumulative_stats = []
    prev_users = 0
    
    # Progress display configuration
    progress_interval = max(1, total_windows // 10)  # Show progress at least 10 times
    
    print("\nðŸ“Š Analysis progress:")
    for i, window_end in enumerate(time_windows):
        # Window statistics
        window_mask = ((df['time_since_start'] > (window_end - delta_t_ms)) & 
                      (df['time_since_start'] <= window_end))
        window_data = df[window_mask]
        
        # Cumulative statistics
        cumulative_data = df[df['time_since_start'] <= window_end]
        
        # Calculate metrics
        window_metrics = calculate_metrics(window_data, user_col)
        cumulative_metrics = calculate_metrics(cumulative_data, user_col)
        
        # Record results
        window_stats.append({'window_end': window_end, **window_metrics})
        cumulative_stats.append({'time_point': window_end, **cumulative_metrics})
        
        # Progress display
        if (i % progress_interval == 0) or (i == total_windows - 1):
            new_users = cumulative_metrics['unique_users'] - prev_users
            progress = (i + 1) / total_windows * 100
            time_elapsed = window_end / 1000
            print(
                f"â–{progress:.0f}% â–Time: {time_elapsed:.1f}s â–"
                f"Window interactions: {window_metrics['total_interactions']:4d} â–"
                f"New users: {new_users:3d} â–"
                f"Total users: {cumulative_metrics['unique_users']:5d}"
            )
            prev_users = cumulative_metrics['unique_users']
    
    # Final statistics
    print("\nâœ… Analysis completed!")
    final_stats = cumulative_stats[-1]
    print(f"â€¢ Total time span: {max_time/1000:.1f} seconds")
    print(f"â€¢ Total users: {final_stats['unique_users']:,}")
    print(f"â€¢ Total interactions: {final_stats['total_interactions']:,}")
    print(f"â€¢ Avg interactions/user: {final_stats['avg_interactions_per_user']:.1f}")
    
    return pd.DataFrame(window_stats), pd.DataFrame(cumulative_stats)

def visualize_results(window_df, cumulative_df, output_path):
    """Enhanced visualization with larger fonts"""
    # ======================
    # 1. å­—ä½“å…¨å±€è®¾ç½®
    # ======================
    plt.style.use('seaborn-v0_8')
    mpl.rcParams.update({
        'font.size': 14,          # å…¨å±€åŸºç¡€å­—å·å¢žå¤§
        'axes.titlesize': 20,     # æ ‡é¢˜å­—å·åŠ å¤§
        'axes.labelsize': 18,     # åæ ‡è½´æ ‡ç­¾
        'xtick.labelsize': 16,    # Xè½´åˆ»åº¦
        'ytick.labelsize': 16,    # Yè½´åˆ»åº¦
        'legend.fontsize': 16,    # å›¾ä¾‹å­—å·
    })

    # ======================
    # 2. åˆ›å»ºç”»å¸ƒï¼ˆè°ƒæ•´DPIï¼‰
    # ======================
    fig = plt.figure(figsize=(20, 15), dpi=120)
    fig.suptitle('User Interaction Analysis', fontsize=22, y=1.02)

    # ======================
    # 3. å­å›¾ç»˜åˆ¶ï¼ˆå­—å·å¼ºåŒ–ï¼‰
    # ======================
    # 3.1 ç´¯è®¡ç”¨æˆ·æ•°ï¼ˆå·¦ä¸Šï¼‰
    ax1 = fig.add_subplot(2, 2, 1)
    ax1.plot(cumulative_df['time_point']/1000, 
            cumulative_df['unique_users'], 
            'b-', linewidth=3)
    ax1.set_title('Cumulative Unique Users', pad=20, fontsize=20)
    ax1.set_xlabel('Time (seconds)', fontsize=18, labelpad=10)
    ax1.set_ylabel('User Count', fontsize=18, labelpad=10)
    ax1.grid(True, alpha=0.3)
    
    # 3.2 çª—å£ç”¨æˆ·æ•°ï¼ˆå³ä¸Šï¼‰- é‡ç‚¹æ”¾å¤§
    ax2 = fig.add_subplot(2, 2, 2)
    bar_width = window_df['window_end'].diff().mean()/1000*0.7
    ax2.bar(window_df['window_end']/1000, 
           window_df['unique_users'],
           width=bar_width,
           color='#FF7F0E', edgecolor='white')
    ax2.set_title('Unique Users per Window', pad=20, fontsize=20)
    ax2.set_xlabel('Time (seconds)', fontsize=18, labelpad=10)
    ax2.set_ylabel('User Count', fontsize=18, labelpad=10)
    ax2.grid(True, axis='y', alpha=0.3)
    
    # 3.3 çª—å£äº¤äº’é‡ï¼ˆå·¦ä¸‹ï¼‰
    ax3 = fig.add_subplot(2, 2, 3)
    ax3.bar(window_df['window_end']/1000, 
           window_df['total_interactions'],
           width=bar_width,
           color='#2CA02C', edgecolor='white')
    ax3.set_title('Interactions per Window', pad=20, fontsize=20)
    ax3.set_xlabel('Time (seconds)', fontsize=18, labelpad=10)
    ax3.set_ylabel('Interaction Count', fontsize=18, labelpad=10)
    ax3.grid(True, axis='y', alpha=0.3)
    
    # 3.4 å¹³å‡äº¤äº’æ¬¡æ•°ï¼ˆå³ä¸‹ï¼‰
    ax4 = fig.add_subplot(2, 2, 4)
    ax4.plot(cumulative_df['time_point']/1000,
            cumulative_df['total_interactions']/cumulative_df['unique_users'],
            'r-', linewidth=3)
    ax4.set_title('Avg Interactions per User', pad=20, fontsize=20)
    ax4.set_xlabel('Time (seconds)', fontsize=18, labelpad=10)
    ax4.set_ylabel('Average Count', fontsize=18, labelpad=10)
    ax4.grid(True, alpha=0.3)

    # ======================
    # 4. è¾“å‡ºä¼˜åŒ–
    # ======================
    plt.tight_layout(pad=3.0)  # å¢žåŠ å­å›¾é—´è·
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"ðŸ“Š Visualization saved with enhanced fonts: {output_path}")

def save_json_distributions(df, output_path):
    """Save distribution data as structured JSON"""
    dist_data = []
    for _, row in df.iterrows():
        dist_data.append({
            'time_point': row['time_point'],
            'user_distribution': {
                'total_users': row['unique_users'],
                'interaction_dist': {
                    str(k): int(v) for k, v in 
                    sorted(row['interaction_counts'].items())
                }
            }
        })
    
    with open(output_path, 'w') as f:
        json.dump(dist_data, f, indent=2)

def check_existing_files(output_dir, output_prefix, delta_t):
    """æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åˆ†æžç»“æžœæ–‡ä»¶"""
    delta_s = delta_t // 1000
    files = {
        'window': os.path.join(output_dir, f"{output_prefix}_window_{delta_s}s.csv"),
        'cumulative': os.path.join(output_dir, f"{output_prefix}_cumulative_{delta_s}s.csv"),
        'json': os.path.join(output_dir, f"{output_prefix}_distributions_{delta_s}s.json"),
        'plot': os.path.join(output_dir, f"{output_prefix}_plot_{delta_s}s.png")
    }
    
    # æ£€æŸ¥æ‰€æœ‰å¿…éœ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    all_exist = all(os.path.exists(f) for f in files.values())
    return files, all_exist

def main():
    args = parse_arguments()
    os.makedirs(args.output_dir, exist_ok=True)
    
    print(f"Analysis started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"Input file: {args.input_file}")
    print(f"Time window: {args.delta_t}ms ({args.delta_t/1000:.1f}s)")
    print(f"Output directory: {args.output_dir}")
    
    try:
        # Load data
        df = pd.read_csv(args.input_file)
        print(f"Successfully loaded {len(df):,} records")
        
        # Analyze data
        window_df, cumulative_df = analyze_data(df, args.delta_t, args.time_col, args.user_col)
        
        # Generate output filenames based on delta_t
        delta_s = args.delta_t // 1000
        window_file = os.path.join(args.output_dir, f"{args.output_prefix}_window_{delta_s}s.csv")
        cumulative_file = os.path.join(args.output_dir, f"{args.output_prefix}_cumulative_{delta_s}s.csv")
        json_file = os.path.join(args.output_dir, f"{args.output_prefix}_distributions_{delta_s}s.json")
        plot_file = os.path.join(args.output_dir, f"{args.output_prefix}_plot_{delta_s}s.png")
        
        # Save results
        window_df.to_csv(window_file, index=False)
        cumulative_df.to_csv(cumulative_file, index=False)
        save_json_distributions(cumulative_df, json_file)
        
        # Visualization
        if args.plot:
            plot_path = visualize_results(window_df, cumulative_df, plot_file)
            print(f"Visualization saved to: {plot_path}")
        
        print("\nAnalysis completed successfully!")
        print(f"Window stats: {window_file}")
        print(f"Cumulative stats: {cumulative_file}")
        print(f"Distribution data: {json_file}")
        if args.plot:
            print(f"Visualization: {plot_path}")
        
    except Exception as e:
        print(f"\nProcessing failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()